{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des données numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(s):\n",
    "    if s == '+':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "credit = pd.read_csv('credit.data', delimiter='\\t', header=None, decimal='.')\n",
    "credit.dropna(thresh=0, inplace=True)\n",
    "credit[15] = credit[15].map(get_value)\n",
    "credit_num = credit.ix[:,(1, 2, 7, 10, 13, 14, 15)]\n",
    "for col in credit_num.columns:\n",
    "    credit_num[col] = pd.to_numeric(credit_num[col], errors='coerce')\n",
    "\n",
    "credit_num.dropna(inplace=True)\n",
    "credit_label = credit_num.loc[:,15]\n",
    "credit_X_num = credit_num.loc[:,(1, 2, 7, 10, 13, 14)]\n",
    "credit_X_num[10] = credit_X_num[10].astype('float64')\n",
    "credit_X_num[14] = credit_X_num[14].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions des données par colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>666.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>666.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.569054</td>\n",
       "      <td>4.798078</td>\n",
       "      <td>2.222320</td>\n",
       "      <td>2.459459</td>\n",
       "      <td>182.115616</td>\n",
       "      <td>998.584084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.920174</td>\n",
       "      <td>5.005309</td>\n",
       "      <td>3.347599</td>\n",
       "      <td>4.929794</td>\n",
       "      <td>171.477919</td>\n",
       "      <td>5202.975198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.602500</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.500000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.250000</td>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.585000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1           2           7           10           13  \\\n",
       "count  666.000000  666.000000  666.000000  666.000000   666.000000   \n",
       "mean    31.569054    4.798078    2.222320    2.459459   182.115616   \n",
       "std     11.920174    5.005309    3.347599    4.929794   171.477919   \n",
       "min     13.750000    0.000000    0.000000    0.000000     0.000000   \n",
       "25%     22.602500    1.010000    0.165000    0.000000    75.250000   \n",
       "50%     28.500000    2.750000    1.000000    0.000000   160.000000   \n",
       "75%     38.250000    7.207500    2.585000    3.000000   271.000000   \n",
       "max     80.250000   28.000000   28.500000   67.000000  2000.000000   \n",
       "\n",
       "                  14  \n",
       "count     666.000000  \n",
       "mean      998.584084  \n",
       "std      5202.975198  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         5.000000  \n",
       "75%       399.000000  \n",
       "max    100000.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_X_num.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Répartition des + et - dans la base d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7e6436ad30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e6436a6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oui = credit_label[credit_label == 1].value_counts()\n",
    "non = credit_label[credit_label == 0].value_counts()\n",
    "df = pd.DataFrame([oui, non])\n",
    "df.index = ['oui','non']\n",
    "df.plot(kind='bar', stacked=True, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonction pour la partie séléction de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_PCA(X, min_acp=.7, replace=False):\n",
    "    res = list()\n",
    "    nb_component = 0\n",
    "    while sum(res)<min_acp:\n",
    "        nb_component += 1\n",
    "        pca = PCA(n_components=nb_component)\n",
    "        pca.fit_transform(X)\n",
    "        res = pca.explained_variance_ratio_\n",
    "    pca = PCA(n_components=nb_component)\n",
    "    if replace:\n",
    "        return pca.fit_transform(X)\n",
    "    else:\n",
    "        ajout = pca.fit_transform(X)\n",
    "        X = np.concatenate((X, ajout), axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonction qui compare tout les modèles passés en argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiers(clfs, X, y, kf, standardisation=False, engineering=False, replace=False, min_acp=.7):\n",
    "    if not standardisation and engineering:\n",
    "        raise AttributeError('you have to scale if you want to add pca variables')\n",
    "    if standardisation:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        \n",
    "    if engineering:\n",
    "        X = ajout_PCA(X, min_acp, replace)\n",
    "    r = list()\n",
    "    for name, clf in clfs.items():\n",
    "        \n",
    "        cv_acc = cross_validate(clf, X, y, cv=kf, scoring=('accuracy', 'roc_auc', 'recall', 'precision'))\n",
    "        r.append([name,\n",
    "                  str(np.round(np.mean(cv_acc['test_accuracy']),4)) + ' +/- ' + str(np.round(np.std(cv_acc['test_accuracy']),4)),\n",
    "                  str(np.round(np.mean(cv_acc['test_roc_auc']),4)) + ' +/- ' + str(np.round(np.std(cv_acc['test_roc_auc']),4)),\n",
    "                  str(np.round(np.mean(cv_acc['test_recall']),4)) + ' +/- ' + str(np.round(np.std(cv_acc['test_recall']),4)),\n",
    "                  str(np.round(np.mean(cv_acc['test_precision']),4)) + ' +/- ' + str(np.round(np.std(cv_acc['test_precision']),4)),\n",
    "                  str(np.round(np.mean(cv_acc['fit_time']),4)) + 's'])\n",
    "    res = pd.DataFrame(r)\n",
    "    res.columns = ['Name', 'Accuracy', 'AUC','Recall','Precision', 'Time']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modèles que l'on va comparer (on a fixé random_state pour pouvoir repreoduire les mêmes réusltats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs={\n",
    "'Tree': DecisionTreeClassifier(random_state=20),\n",
    "'RF': RandomForestClassifier(n_estimators=50, random_state=20),\n",
    "'Bagg': BaggingClassifier(n_estimators=50, random_state=20),\n",
    "'KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=20),\n",
    "'SVM': SVC(),\n",
    "'XGBOOST': XGBClassifier(\n",
    " n_estimators=50,\n",
    " seed=20),\n",
    "\"MLPC\": MLPClassifier(hidden_layer_sizes=(20, 10))\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.6923 +/- 0.0474</td>\n",
       "      <td>0.6921 +/- 0.0493</td>\n",
       "      <td>0.6552 +/- 0.0911</td>\n",
       "      <td>0.6612 +/- 0.0612</td>\n",
       "      <td>0.0031s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.7839 +/- 0.061</td>\n",
       "      <td>0.85 +/- 0.0588</td>\n",
       "      <td>0.7214 +/- 0.1066</td>\n",
       "      <td>0.792 +/- 0.1082</td>\n",
       "      <td>0.0734s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagg</td>\n",
       "      <td>0.7733 +/- 0.0607</td>\n",
       "      <td>0.8476 +/- 0.053</td>\n",
       "      <td>0.695 +/- 0.1175</td>\n",
       "      <td>0.7917 +/- 0.1162</td>\n",
       "      <td>0.0956s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.6563 +/- 0.0547</td>\n",
       "      <td>0.6501 +/- 0.0608</td>\n",
       "      <td>0.5659 +/- 0.1179</td>\n",
       "      <td>0.6289 +/- 0.0937</td>\n",
       "      <td>0.001s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7763 +/- 0.0491</td>\n",
       "      <td>0.8532 +/- 0.0431</td>\n",
       "      <td>0.7191 +/- 0.1143</td>\n",
       "      <td>0.7796 +/- 0.0949</td>\n",
       "      <td>0.0691s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.5464 +/- 0.0458</td>\n",
       "      <td>0.6702 +/- 0.0599</td>\n",
       "      <td>0.0308 +/- 0.0245</td>\n",
       "      <td>0.365 +/- 0.2984</td>\n",
       "      <td>0.0137s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.7913 +/- 0.047</td>\n",
       "      <td>0.8637 +/- 0.0453</td>\n",
       "      <td>0.7088 +/- 0.1019</td>\n",
       "      <td>0.8136 +/- 0.0837</td>\n",
       "      <td>0.016s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.6443 +/- 0.0984</td>\n",
       "      <td>0.6621 +/- 0.1362</td>\n",
       "      <td>0.6014 +/- 0.2158</td>\n",
       "      <td>0.6225 +/- 0.1371</td>\n",
       "      <td>0.0412s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name           Accuracy                AUC             Recall  \\\n",
       "0      Tree  0.6923 +/- 0.0474  0.6921 +/- 0.0493  0.6552 +/- 0.0911   \n",
       "1        RF   0.7839 +/- 0.061    0.85 +/- 0.0588  0.7214 +/- 0.1066   \n",
       "2      Bagg  0.7733 +/- 0.0607   0.8476 +/- 0.053   0.695 +/- 0.1175   \n",
       "3       KNN  0.6563 +/- 0.0547  0.6501 +/- 0.0608  0.5659 +/- 0.1179   \n",
       "4  AdaBoost  0.7763 +/- 0.0491  0.8532 +/- 0.0431  0.7191 +/- 0.1143   \n",
       "5       SVM  0.5464 +/- 0.0458  0.6702 +/- 0.0599  0.0308 +/- 0.0245   \n",
       "6   XGBOOST   0.7913 +/- 0.047  0.8637 +/- 0.0453  0.7088 +/- 0.1019   \n",
       "7      MLPC  0.6443 +/- 0.0984  0.6621 +/- 0.1362  0.6014 +/- 0.2158   \n",
       "\n",
       "           Precision     Time  \n",
       "0  0.6612 +/- 0.0612  0.0031s  \n",
       "1   0.792 +/- 0.1082  0.0734s  \n",
       "2  0.7917 +/- 0.1162  0.0956s  \n",
       "3  0.6289 +/- 0.0937   0.001s  \n",
       "4  0.7796 +/- 0.0949  0.0691s  \n",
       "5   0.365 +/- 0.2984  0.0137s  \n",
       "6  0.8136 +/- 0.0837   0.016s  \n",
       "7  0.6225 +/- 0.1371  0.0412s  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifiers(clfs, credit_X_num, credit_label, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le SVM ne fonctionne pas très bien sans normalisation.\n",
    "On voit aussi que les methodes ensemblistes semblent bien fonctionner sans avoir encore cherché les \"meilleurs\" hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.6908 +/- 0.048</td>\n",
       "      <td>0.6905 +/- 0.0497</td>\n",
       "      <td>0.6552 +/- 0.0911</td>\n",
       "      <td>0.6582 +/- 0.057</td>\n",
       "      <td>0.0025s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.7839 +/- 0.061</td>\n",
       "      <td>0.8496 +/- 0.058</td>\n",
       "      <td>0.7214 +/- 0.1066</td>\n",
       "      <td>0.792 +/- 0.1082</td>\n",
       "      <td>0.0725s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagg</td>\n",
       "      <td>0.7749 +/- 0.0597</td>\n",
       "      <td>0.8479 +/- 0.0525</td>\n",
       "      <td>0.698 +/- 0.1152</td>\n",
       "      <td>0.7923 +/- 0.1165</td>\n",
       "      <td>0.0957s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7163 +/- 0.0298</td>\n",
       "      <td>0.7172 +/- 0.0314</td>\n",
       "      <td>0.6696 +/- 0.1089</td>\n",
       "      <td>0.7027 +/- 0.0777</td>\n",
       "      <td>0.0006s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7763 +/- 0.0491</td>\n",
       "      <td>0.8532 +/- 0.0431</td>\n",
       "      <td>0.7191 +/- 0.1143</td>\n",
       "      <td>0.7796 +/- 0.0949</td>\n",
       "      <td>0.0692s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7688 +/- 0.0633</td>\n",
       "      <td>0.8444 +/- 0.0489</td>\n",
       "      <td>0.6118 +/- 0.1108</td>\n",
       "      <td>0.844 +/- 0.0967</td>\n",
       "      <td>0.01s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.7928 +/- 0.0468</td>\n",
       "      <td>0.8638 +/- 0.0454</td>\n",
       "      <td>0.7088 +/- 0.1019</td>\n",
       "      <td>0.817 +/- 0.0812</td>\n",
       "      <td>0.0108s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.7869 +/- 0.066</td>\n",
       "      <td>0.8479 +/- 0.0501</td>\n",
       "      <td>0.6905 +/- 0.113</td>\n",
       "      <td>0.812 +/- 0.0806</td>\n",
       "      <td>0.2895s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name           Accuracy                AUC             Recall  \\\n",
       "0      Tree   0.6908 +/- 0.048  0.6905 +/- 0.0497  0.6552 +/- 0.0911   \n",
       "1        RF   0.7839 +/- 0.061   0.8496 +/- 0.058  0.7214 +/- 0.1066   \n",
       "2      Bagg  0.7749 +/- 0.0597  0.8479 +/- 0.0525   0.698 +/- 0.1152   \n",
       "3       KNN  0.7163 +/- 0.0298  0.7172 +/- 0.0314  0.6696 +/- 0.1089   \n",
       "4  AdaBoost  0.7763 +/- 0.0491  0.8532 +/- 0.0431  0.7191 +/- 0.1143   \n",
       "5       SVM  0.7688 +/- 0.0633  0.8444 +/- 0.0489  0.6118 +/- 0.1108   \n",
       "6   XGBOOST  0.7928 +/- 0.0468  0.8638 +/- 0.0454  0.7088 +/- 0.1019   \n",
       "7      MLPC   0.7869 +/- 0.066  0.8479 +/- 0.0501   0.6905 +/- 0.113   \n",
       "\n",
       "           Precision     Time  \n",
       "0   0.6582 +/- 0.057  0.0025s  \n",
       "1   0.792 +/- 0.1082  0.0725s  \n",
       "2  0.7923 +/- 0.1165  0.0957s  \n",
       "3  0.7027 +/- 0.0777  0.0006s  \n",
       "4  0.7796 +/- 0.0949  0.0692s  \n",
       "5   0.844 +/- 0.0967    0.01s  \n",
       "6   0.817 +/- 0.0812  0.0108s  \n",
       "7   0.812 +/- 0.0806  0.2895s  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifiers(clfs, credit_X_num, credit_label, kf, standardisation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'après normalisation, MLPC, SVM et KNN performent bien mieux que sans alors que pour les méthodes ensemblistes et l'arbre de décision, cela n'a rien changé de manière significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.6653 +/- 0.0626</td>\n",
       "      <td>0.669 +/- 0.0658</td>\n",
       "      <td>0.644 +/- 0.1329</td>\n",
       "      <td>0.6306 +/- 0.085</td>\n",
       "      <td>0.0032s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.7209 +/- 0.0574</td>\n",
       "      <td>0.7973 +/- 0.053</td>\n",
       "      <td>0.6516 +/- 0.1205</td>\n",
       "      <td>0.7164 +/- 0.0858</td>\n",
       "      <td>0.0802s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagg</td>\n",
       "      <td>0.718 +/- 0.0593</td>\n",
       "      <td>0.7893 +/- 0.0431</td>\n",
       "      <td>0.6334 +/- 0.1073</td>\n",
       "      <td>0.7169 +/- 0.1001</td>\n",
       "      <td>0.0958s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7073 +/- 0.0554</td>\n",
       "      <td>0.7097 +/- 0.0546</td>\n",
       "      <td>0.6579 +/- 0.1069</td>\n",
       "      <td>0.6966 +/- 0.1097</td>\n",
       "      <td>0.0005s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.727 +/- 0.0612</td>\n",
       "      <td>0.7844 +/- 0.0538</td>\n",
       "      <td>0.6576 +/- 0.078</td>\n",
       "      <td>0.7169 +/- 0.1008</td>\n",
       "      <td>0.0706s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7417 +/- 0.0672</td>\n",
       "      <td>0.7967 +/- 0.0585</td>\n",
       "      <td>0.561 +/- 0.1187</td>\n",
       "      <td>0.8174 +/- 0.0936</td>\n",
       "      <td>0.0101s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.7358 +/- 0.0452</td>\n",
       "      <td>0.8004 +/- 0.0445</td>\n",
       "      <td>0.6476 +/- 0.0745</td>\n",
       "      <td>0.7433 +/- 0.0868</td>\n",
       "      <td>0.0102s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.7509 +/- 0.0698</td>\n",
       "      <td>0.8089 +/- 0.061</td>\n",
       "      <td>0.6285 +/- 0.1147</td>\n",
       "      <td>0.7824 +/- 0.0975</td>\n",
       "      <td>0.2819s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name           Accuracy                AUC             Recall  \\\n",
       "0      Tree  0.6653 +/- 0.0626   0.669 +/- 0.0658   0.644 +/- 0.1329   \n",
       "1        RF  0.7209 +/- 0.0574   0.7973 +/- 0.053  0.6516 +/- 0.1205   \n",
       "2      Bagg   0.718 +/- 0.0593  0.7893 +/- 0.0431  0.6334 +/- 0.1073   \n",
       "3       KNN  0.7073 +/- 0.0554  0.7097 +/- 0.0546  0.6579 +/- 0.1069   \n",
       "4  AdaBoost   0.727 +/- 0.0612  0.7844 +/- 0.0538   0.6576 +/- 0.078   \n",
       "5       SVM  0.7417 +/- 0.0672  0.7967 +/- 0.0585   0.561 +/- 0.1187   \n",
       "6   XGBOOST  0.7358 +/- 0.0452  0.8004 +/- 0.0445  0.6476 +/- 0.0745   \n",
       "7      MLPC  0.7509 +/- 0.0698   0.8089 +/- 0.061  0.6285 +/- 0.1147   \n",
       "\n",
       "           Precision     Time  \n",
       "0   0.6306 +/- 0.085  0.0032s  \n",
       "1  0.7164 +/- 0.0858  0.0802s  \n",
       "2  0.7169 +/- 0.1001  0.0958s  \n",
       "3  0.6966 +/- 0.1097  0.0005s  \n",
       "4  0.7169 +/- 0.1008  0.0706s  \n",
       "5  0.8174 +/- 0.0936  0.0101s  \n",
       "6  0.7433 +/- 0.0868  0.0102s  \n",
       "7  0.7824 +/- 0.0975  0.2819s  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifiers(clfs, credit_X_num, credit_label, kf, standardisation=True,engineering=True, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on remplace toute les variables explicatives par leurs projections sur les composantes principales, les performances sont moins bonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.7223 +/- 0.0389</td>\n",
       "      <td>0.7249 +/- 0.0401</td>\n",
       "      <td>0.7042 +/- 0.0952</td>\n",
       "      <td>0.6939 +/- 0.0795</td>\n",
       "      <td>0.0057s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.7779 +/- 0.0493</td>\n",
       "      <td>0.8489 +/- 0.0496</td>\n",
       "      <td>0.7121 +/- 0.0998</td>\n",
       "      <td>0.7904 +/- 0.1</td>\n",
       "      <td>0.0839s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagg</td>\n",
       "      <td>0.7689 +/- 0.0477</td>\n",
       "      <td>0.8516 +/- 0.0507</td>\n",
       "      <td>0.7037 +/- 0.1167</td>\n",
       "      <td>0.7802 +/- 0.1005</td>\n",
       "      <td>0.1435s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7148 +/- 0.0393</td>\n",
       "      <td>0.7161 +/- 0.0408</td>\n",
       "      <td>0.6644 +/- 0.1167</td>\n",
       "      <td>0.7035 +/- 0.082</td>\n",
       "      <td>0.0006s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7853 +/- 0.0357</td>\n",
       "      <td>0.8465 +/- 0.0477</td>\n",
       "      <td>0.7261 +/- 0.0808</td>\n",
       "      <td>0.7873 +/- 0.0778</td>\n",
       "      <td>0.0836s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7688 +/- 0.0587</td>\n",
       "      <td>0.8389 +/- 0.0475</td>\n",
       "      <td>0.607 +/- 0.0874</td>\n",
       "      <td>0.8475 +/- 0.1049</td>\n",
       "      <td>0.0109s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.7884 +/- 0.0517</td>\n",
       "      <td>0.8617 +/- 0.0539</td>\n",
       "      <td>0.6941 +/- 0.1164</td>\n",
       "      <td>0.8152 +/- 0.0769</td>\n",
       "      <td>0.0161s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.7958 +/- 0.0486</td>\n",
       "      <td>0.8618 +/- 0.0388</td>\n",
       "      <td>0.7074 +/- 0.1014</td>\n",
       "      <td>0.82 +/- 0.0712</td>\n",
       "      <td>0.2969s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name           Accuracy                AUC             Recall  \\\n",
       "0      Tree  0.7223 +/- 0.0389  0.7249 +/- 0.0401  0.7042 +/- 0.0952   \n",
       "1        RF  0.7779 +/- 0.0493  0.8489 +/- 0.0496  0.7121 +/- 0.0998   \n",
       "2      Bagg  0.7689 +/- 0.0477  0.8516 +/- 0.0507  0.7037 +/- 0.1167   \n",
       "3       KNN  0.7148 +/- 0.0393  0.7161 +/- 0.0408  0.6644 +/- 0.1167   \n",
       "4  AdaBoost  0.7853 +/- 0.0357  0.8465 +/- 0.0477  0.7261 +/- 0.0808   \n",
       "5       SVM  0.7688 +/- 0.0587  0.8389 +/- 0.0475   0.607 +/- 0.0874   \n",
       "6   XGBOOST  0.7884 +/- 0.0517  0.8617 +/- 0.0539  0.6941 +/- 0.1164   \n",
       "7      MLPC  0.7958 +/- 0.0486  0.8618 +/- 0.0388  0.7074 +/- 0.1014   \n",
       "\n",
       "           Precision     Time  \n",
       "0  0.6939 +/- 0.0795  0.0057s  \n",
       "1     0.7904 +/- 0.1  0.0839s  \n",
       "2  0.7802 +/- 0.1005  0.1435s  \n",
       "3   0.7035 +/- 0.082  0.0006s  \n",
       "4  0.7873 +/- 0.0778  0.0836s  \n",
       "5  0.8475 +/- 0.1049  0.0109s  \n",
       "6  0.8152 +/- 0.0769  0.0161s  \n",
       "7    0.82 +/- 0.0712  0.2969s  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifiers(clfs, credit_X_num, credit_label, kf, standardisation=True, engineering=True, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on rajoute aux variables explicatives leurs projections sur les composantes principales, les performances des modèles semblent s'améliorer, surtout pour XGBOOST et MLPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans avoir chercher à tuner les hyperparamètres, on voit qu'il est important de transformer les données pour avoir des modèles plus performants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent essayer de tuner les hyperparamètres de 3 modèles, RF, XGBOOST et SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'affchage des performances des modèles\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va garder la version avec Normalisation et engineering\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(credit_X_num)\n",
    "X = ajout_PCA(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le critère le plus important entre recall et precision est pour nous précision. En effet il nous semble qu'il est plus important de ne pas se tromper lorsqu'on accorde un crédit plutôt que d'essayer d'accorder un crédit aux plus grand nombre qui risque d'être très préjudiciable si on se trompe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser un randomizedSearch pour trouver une bonne combinaison d'hyperparamètres permettant d'augmenter la précision car c'est comme on l'a dit le critère qui semble être le plus important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.905 (std: 0.094)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 1, 'max_features': 1, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 107}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.877 (std: 0.092)\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 1, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 155}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.875 (std: 0.073)\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 1, 'max_features': 3, 'min_samples_leaf': 8, 'min_samples_split': 7, 'n_estimators': 21}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as unif\n",
    "#scoring = {'AUC': 'roc_auc', 'Accuracy': 'accuracy'}\n",
    "param_dist = {\"max_depth\": sp_randint(1,20),\n",
    "              \"max_features\": sp_randint(1, 6),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"n_estimators\": sp_randint(20, 200),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rs = RandomizedSearchCV(RandomForestClassifier(random_state=42),\n",
    "                   cv=kf, refit=False, param_distributions=param_dist, n_iter=100,scoring=\"precision\", verbose=1, n_jobs=-1)\n",
    "rs.fit(X, credit_label)\n",
    "report(rs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit les 3 jeux d'hyperparamètres qui donnent la meilleur performance en terme de précision pour le modèle RandomForrest, après 100 itérations.\n",
    "Les résultats montrent que ces modèles sont beaucoup plus performant selon ce critère qu'avec les hyperparamètres par défaut de sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 479 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 979 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1679 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2579 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4005 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5307 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7217 tasks      | elapsed:  4.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.839 (std: 0.114)\n",
      "Parameters: {'colsample_bytree': 0.64999999999999991, 'gamma': 0.82094263335786788, 'learning_rate': 0.02485915256988791, 'max_depth': 3, 'n_estimators': 71, 'reg_alpha': 0.004868024116561287, 'reg_lambda': 0.69043301226536935, 'subsample': 0.20311286417959473}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.830 (std: 0.116)\n",
      "Parameters: {'colsample_bytree': 0.34999999999999998, 'gamma': 0.52764785121122992, 'learning_rate': 0.030792514204779131, 'max_depth': 8, 'n_estimators': 88, 'reg_alpha': 0.91952274074656937, 'reg_lambda': 0.23310961447759027, 'subsample': 0.05943241941380073}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.829 (std: 0.084)\n",
      "Parameters: {'colsample_bytree': 0.84999999999999987, 'gamma': 0.78612249731847683, 'learning_rate': 0.0042540494388217942, 'max_depth': 2, 'n_estimators': 151, 'reg_alpha': 0.43798094619122552, 'reg_lambda': 0.81429189411436254, 'subsample': 0.74008965192160148}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  6.2min finished\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'max_depth': sp_randint(1, 10),\n",
    "              'learning_rate': unif(0, 1),\n",
    "              'n_estimators': sp_randint(50, 500),\n",
    "              'gamma': unif(0, 1),\n",
    "              'reg_alpha': unif(0, 1),\n",
    "              'reg_lambda': unif(0, 1),\n",
    "              'subsample' : unif(0, 1),\n",
    "              'colsample_bytree' : np.arange(.3, 1, .05)\n",
    "             }\n",
    "\n",
    "rs = RandomizedSearchCV(XGBClassifier(seed=20, nthread=1, silent=True),\n",
    "                   cv=kf, param_distributions=param_dist, n_iter=1000, scoring='precision', verbose=1, n_jobs=-1)\n",
    "rs.fit(X, credit_label)\n",
    "report(rs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit les 3 jeux d'hyperparamètres qui donnent la meilleur performance en terme de précision pour le modèle XGBOOST après 1000 itérations.\n",
    "Les résultats montrent que ces modèles sont légérements plus performant selon ce critère qu'avec les hyperparamètres par défaut de sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1616 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3824 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6904 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.950 (std: 0.150)\n",
      "Parameters: {'C': 2.5, 'gamma': 0.00019198517428442585, 'kernel': 'sigmoid'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.903 (std: 0.078)\n",
      "Parameters: {'C': 4.0, 'gamma': 0.0010528906352473832, 'kernel': 'sigmoid'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.902 (std: 0.081)\n",
      "Parameters: {'C': 3.0, 'gamma': 0.0028648153488537442, 'kernel': 'sigmoid'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'C':[0.5 + 0.5*i for i in range(10)],\n",
    "              'gamma': unif(0, 1),\n",
    "              'kernel':  ['linear', 'rbf', 'sigmoid']\n",
    "             }\n",
    "\n",
    "rs = RandomizedSearchCV(SVC(random_state=20),\n",
    "                   cv=kf, param_distributions=param_dist, n_iter=1000,scoring='precision', verbose=.5, n_jobs=-1)\n",
    "rs.fit(X, credit_label)\n",
    "report(rs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit les 3 jeux d'hyperparamètres qui donnent la meilleur performance en terme de précision pour le modèle SVM après 1000 itérations.\n",
    "Les résultats montrent que ces modèles sont bien plus performant selon ce critère qu'avec les hyperparamètres par défaut de sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5dbad1e7b8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5db8663a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(X)\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n",
    "clf = clf.fit(X, credit_label)\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = df.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "features.plot(kind='barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_important(X, importance, min_take=.08):\n",
    "    res = [X[:,i] for i, x in enumerate(X[0,:]) if importance[i]> min_take ]\n",
    "    return np.array(res).T\n",
    "\n",
    "X_select = keep_important(X, clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.7163 +/- 0.0442</td>\n",
       "      <td>0.7173 +/- 0.0467</td>\n",
       "      <td>0.6828 +/- 0.1059</td>\n",
       "      <td>0.6911 +/- 0.0875</td>\n",
       "      <td>0.0028s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.7538 +/- 0.0538</td>\n",
       "      <td>0.8337 +/- 0.0486</td>\n",
       "      <td>0.6739 +/- 0.1276</td>\n",
       "      <td>0.7563 +/- 0.0671</td>\n",
       "      <td>0.0751s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagg</td>\n",
       "      <td>0.7704 +/- 0.0454</td>\n",
       "      <td>0.8325 +/- 0.0458</td>\n",
       "      <td>0.6907 +/- 0.1181</td>\n",
       "      <td>0.7842 +/- 0.0905</td>\n",
       "      <td>0.1008s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.7149 +/- 0.0523</td>\n",
       "      <td>0.7106 +/- 0.0549</td>\n",
       "      <td>0.6451 +/- 0.0986</td>\n",
       "      <td>0.6982 +/- 0.0857</td>\n",
       "      <td>0.0013s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7674 +/- 0.0353</td>\n",
       "      <td>0.8487 +/- 0.0444</td>\n",
       "      <td>0.7054 +/- 0.1092</td>\n",
       "      <td>0.7655 +/- 0.0784</td>\n",
       "      <td>0.0747s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7538 +/- 0.0581</td>\n",
       "      <td>0.833 +/- 0.0504</td>\n",
       "      <td>0.5763 +/- 0.1033</td>\n",
       "      <td>0.8371 +/- 0.0968</td>\n",
       "      <td>0.0107s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.787 +/- 0.0482</td>\n",
       "      <td>0.8565 +/- 0.041</td>\n",
       "      <td>0.682 +/- 0.1123</td>\n",
       "      <td>0.8202 +/- 0.0891</td>\n",
       "      <td>0.0129s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.7614 +/- 0.0464</td>\n",
       "      <td>0.8368 +/- 0.0464</td>\n",
       "      <td>0.657 +/- 0.0794</td>\n",
       "      <td>0.7882 +/- 0.0901</td>\n",
       "      <td>0.2843s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name           Accuracy                AUC             Recall  \\\n",
       "0      Tree  0.7163 +/- 0.0442  0.7173 +/- 0.0467  0.6828 +/- 0.1059   \n",
       "1        RF  0.7538 +/- 0.0538  0.8337 +/- 0.0486  0.6739 +/- 0.1276   \n",
       "2      Bagg  0.7704 +/- 0.0454  0.8325 +/- 0.0458  0.6907 +/- 0.1181   \n",
       "3       KNN  0.7149 +/- 0.0523  0.7106 +/- 0.0549  0.6451 +/- 0.0986   \n",
       "4  AdaBoost  0.7674 +/- 0.0353  0.8487 +/- 0.0444  0.7054 +/- 0.1092   \n",
       "5       SVM  0.7538 +/- 0.0581   0.833 +/- 0.0504  0.5763 +/- 0.1033   \n",
       "6   XGBOOST   0.787 +/- 0.0482   0.8565 +/- 0.041   0.682 +/- 0.1123   \n",
       "7      MLPC  0.7614 +/- 0.0464  0.8368 +/- 0.0464   0.657 +/- 0.0794   \n",
       "\n",
       "           Precision     Time  \n",
       "0  0.6911 +/- 0.0875  0.0028s  \n",
       "1  0.7563 +/- 0.0671  0.0751s  \n",
       "2  0.7842 +/- 0.0905  0.1008s  \n",
       "3  0.6982 +/- 0.0857  0.0013s  \n",
       "4  0.7655 +/- 0.0784  0.0747s  \n",
       "5  0.8371 +/- 0.0968  0.0107s  \n",
       "6  0.8202 +/- 0.0891  0.0129s  \n",
       "7  0.7882 +/- 0.0901  0.2843s  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifiers(clfs, X_select, credit_label, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances ne sont pas significativement meilleur que sans séléction de variables avec les modèles par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('credit.data', delimiter='\\t', header=None, decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = [1, 2, 7, 10, 13, 14]\n",
    "col_cat = [i for i in range(0, 15) if i not in col_num]\n",
    "X = credit.values\n",
    "X_cat = np.copy(X[:,col_cat])\n",
    "y = [get_value(x) for x in X[:,15]]\n",
    "for col_id in range(len(col_cat)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "\n",
    "imp_cat = Imputer(missing_values=0, strategy='most_frequent')\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])\n",
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()\n",
    "X_num = np.copy(X[:, col_num])\n",
    "X_num[X_num == '?'] = np.nan\n",
    "X_num = X_num.astype(float)\n",
    "imp_num = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(X_num)\n",
    "X_num = ajout_PCA(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((X_num, X_cat_bin), axis=1)\n",
    "# le jeu de donnée complet est data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5db81d7940>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5db8315400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n",
    "clf = clf.fit(data, y)\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = df.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "features.plot(kind='barh', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisi de garder que les variables qui ont une \"importantce\" supérieur à 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = keep_important(data, clf.feature_importances_, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.785 +/- 0.0486</td>\n",
       "      <td>0.7857 +/- 0.0509</td>\n",
       "      <td>0.7775 +/- 0.0751</td>\n",
       "      <td>0.7498 +/- 0.065</td>\n",
       "      <td>0.0042s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.8634 +/- 0.0317</td>\n",
       "      <td>0.9208 +/- 0.0257</td>\n",
       "      <td>0.8484 +/- 0.0478</td>\n",
       "      <td>0.8428 +/- 0.0623</td>\n",
       "      <td>0.0766s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagg</td>\n",
       "      <td>0.8504 +/- 0.028</td>\n",
       "      <td>0.9181 +/- 0.0203</td>\n",
       "      <td>0.835 +/- 0.0433</td>\n",
       "      <td>0.8255 +/- 0.0633</td>\n",
       "      <td>0.1325s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.8082 +/- 0.0351</td>\n",
       "      <td>0.8065 +/- 0.0346</td>\n",
       "      <td>0.7695 +/- 0.0498</td>\n",
       "      <td>0.7931 +/- 0.0769</td>\n",
       "      <td>0.0006s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.8416 +/- 0.0322</td>\n",
       "      <td>0.9119 +/- 0.028</td>\n",
       "      <td>0.835 +/- 0.0716</td>\n",
       "      <td>0.8087 +/- 0.0599</td>\n",
       "      <td>0.0831s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8519 +/- 0.0306</td>\n",
       "      <td>0.9127 +/- 0.0271</td>\n",
       "      <td>0.9177 +/- 0.0405</td>\n",
       "      <td>0.7816 +/- 0.0597</td>\n",
       "      <td>0.0106s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBOOST</td>\n",
       "      <td>0.8577 +/- 0.0262</td>\n",
       "      <td>0.9308 +/- 0.0168</td>\n",
       "      <td>0.8498 +/- 0.0539</td>\n",
       "      <td>0.8315 +/- 0.0664</td>\n",
       "      <td>0.022s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPC</td>\n",
       "      <td>0.849 +/- 0.0437</td>\n",
       "      <td>0.9189 +/- 0.0267</td>\n",
       "      <td>0.855 +/- 0.0689</td>\n",
       "      <td>0.8096 +/- 0.0633</td>\n",
       "      <td>0.2308s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name           Accuracy                AUC             Recall  \\\n",
       "0      Tree   0.785 +/- 0.0486  0.7857 +/- 0.0509  0.7775 +/- 0.0751   \n",
       "1        RF  0.8634 +/- 0.0317  0.9208 +/- 0.0257  0.8484 +/- 0.0478   \n",
       "2      Bagg   0.8504 +/- 0.028  0.9181 +/- 0.0203   0.835 +/- 0.0433   \n",
       "3       KNN  0.8082 +/- 0.0351  0.8065 +/- 0.0346  0.7695 +/- 0.0498   \n",
       "4  AdaBoost  0.8416 +/- 0.0322   0.9119 +/- 0.028   0.835 +/- 0.0716   \n",
       "5       SVM  0.8519 +/- 0.0306  0.9127 +/- 0.0271  0.9177 +/- 0.0405   \n",
       "6   XGBOOST  0.8577 +/- 0.0262  0.9308 +/- 0.0168  0.8498 +/- 0.0539   \n",
       "7      MLPC   0.849 +/- 0.0437  0.9189 +/- 0.0267   0.855 +/- 0.0689   \n",
       "\n",
       "           Precision     Time  \n",
       "0   0.7498 +/- 0.065  0.0042s  \n",
       "1  0.8428 +/- 0.0623  0.0766s  \n",
       "2  0.8255 +/- 0.0633  0.1325s  \n",
       "3  0.7931 +/- 0.0769  0.0006s  \n",
       "4  0.8087 +/- 0.0599  0.0831s  \n",
       "5  0.7816 +/- 0.0597  0.0106s  \n",
       "6  0.8315 +/- 0.0664   0.022s  \n",
       "7  0.8096 +/- 0.0633  0.2308s  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifiers(clfs, data_select, y, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la performance des classifiers est globalement bien meilleure même sans avoir chercher les hyperparamètres \"optimaux\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
